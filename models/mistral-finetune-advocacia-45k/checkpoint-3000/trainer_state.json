{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.430643767118454,
      "learning_rate": 4.868e-05,
      "loss": 5.6804,
      "step": 100
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.28099215030670166,
      "learning_rate": 4.7346666666666665e-05,
      "loss": 5.5891,
      "step": 200
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2171647995710373,
      "learning_rate": 4.6013333333333336e-05,
      "loss": 5.5793,
      "step": 300
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.1854924112558365,
      "learning_rate": 4.468e-05,
      "loss": 5.5764,
      "step": 400
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.1793888807296753,
      "learning_rate": 4.334666666666667e-05,
      "loss": 5.5701,
      "step": 500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.13798558712005615,
      "learning_rate": 4.201333333333334e-05,
      "loss": 5.5777,
      "step": 600
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.1660473495721817,
      "learning_rate": 4.0680000000000004e-05,
      "loss": 5.574,
      "step": 700
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.15546005964279175,
      "learning_rate": 3.9346666666666674e-05,
      "loss": 5.5695,
      "step": 800
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.14730146527290344,
      "learning_rate": 3.801333333333333e-05,
      "loss": 5.5783,
      "step": 900
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.2502628266811371,
      "learning_rate": 3.668e-05,
      "loss": 5.5734,
      "step": 1000
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.1468394547700882,
      "learning_rate": 3.5346666666666665e-05,
      "loss": 5.5689,
      "step": 1100
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12407389283180237,
      "learning_rate": 3.4013333333333335e-05,
      "loss": 5.5718,
      "step": 1200
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.13046009838581085,
      "learning_rate": 3.268e-05,
      "loss": 5.5746,
      "step": 1300
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.12894389033317566,
      "learning_rate": 3.134666666666667e-05,
      "loss": 5.5724,
      "step": 1400
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.12193717807531357,
      "learning_rate": 3.0013333333333333e-05,
      "loss": 5.5761,
      "step": 1500
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.13825958967208862,
      "learning_rate": 2.868e-05,
      "loss": 5.5697,
      "step": 1600
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.1289459466934204,
      "learning_rate": 2.734666666666667e-05,
      "loss": 5.5677,
      "step": 1700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12633016705513,
      "learning_rate": 2.6013333333333334e-05,
      "loss": 5.5766,
      "step": 1800
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.11886831372976303,
      "learning_rate": 2.468e-05,
      "loss": 5.5727,
      "step": 1900
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.10885661840438843,
      "learning_rate": 2.3346666666666668e-05,
      "loss": 5.5746,
      "step": 2000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.12988778948783875,
      "learning_rate": 2.201333333333333e-05,
      "loss": 5.5854,
      "step": 2100
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.13352499902248383,
      "learning_rate": 2.0680000000000002e-05,
      "loss": 5.5824,
      "step": 2200
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.09360824525356293,
      "learning_rate": 1.934666666666667e-05,
      "loss": 5.5755,
      "step": 2300
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10610861331224442,
      "learning_rate": 1.8013333333333336e-05,
      "loss": 5.5707,
      "step": 2400
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.10474128276109695,
      "learning_rate": 1.668e-05,
      "loss": 5.5664,
      "step": 2500
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.10205205529928207,
      "learning_rate": 1.5346666666666667e-05,
      "loss": 5.5677,
      "step": 2600
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12192981690168381,
      "learning_rate": 1.4013333333333334e-05,
      "loss": 5.5651,
      "step": 2700
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.12664185464382172,
      "learning_rate": 1.268e-05,
      "loss": 5.5685,
      "step": 2800
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.1263880580663681,
      "learning_rate": 1.1346666666666666e-05,
      "loss": 5.5702,
      "step": 2900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.10116566717624664,
      "learning_rate": 1.0013333333333335e-05,
      "loss": 5.5669,
      "step": 3000
    }
  ],
  "logging_steps": 100,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.573518009434112e+18,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
